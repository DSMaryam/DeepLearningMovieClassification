{"cells":[{"cell_type":"code","metadata":{"tags":[],"cell_id":"9b5eaf95-00b5-4a18-a121-5653c896ef05"},"source":"import csv\r\nfrom pathlib import Path \r\nimport numpy as np\r\nfrom keras.preprocessing.text import Tokenizer\r\nfrom sklearn.utils import shuffle\r\nfrom keras.preprocessing import sequence\r\nimport os \r\nfrom keras.models import Sequential\r\nfrom keras.layers import Dense, Dropout, Activation\r\nfrom keras.layers import Embedding, Reshape\r\nfrom keras.layers import LSTM\r\nfrom keras.layers import Conv1D, MaxPooling1D\r\nfrom keras.utils import np_utils\r\n\r\nfrom sklearn.model_selection import cross_val_score\r\nfrom sklearn.model_selection import KFold\r\nfrom sklearn.preprocessing import LabelEncoder\r\nfrom sklearn.pipeline import Pipeline\r\n","outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"c2b0f9f7-4e47-4c8a-8ce0-dabad243f280"},"source":"max_features = 20000\r\nmaxlen = 100\r\n\r\nYtrain=[]\r\ntrainx=[]\r\nYtest=[]\r\ntestx=[]\r\nprint(\"loading the data...\")\r\nwith open('out5.csv',errors='ignore') as csv_file:\r\n    csv_reader = csv.reader(csv_file, delimiter = '\\t')\r\n    for row in csv_reader:\r\n        if csv_reader.line_num < 170001:\r\n            Ytrain.append(int(row[0].split('/')[0]))\r\n            trainx.append(row[1])\r\n        elif csv_reader.line_num < 190001:\r\n            Ytest.append(int(row[0].split('/')[0]))\r\n            testx.append(row[1]) \r\n        else:\r\n            break    \r\n\r\n#194869\r\n\r\n\r\nprint(\"data loaded, processing data...\")\r\n\r\n\r\n# create the tokenizer\r\ntok= Tokenizer(num_words=max_features, lower=True,filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',split=' ', char_level=False, oov_token=None, document_count=0)\r\n# fit the tokenizer on the documents\r\ntok.fit_on_texts(trainx)\r\n# summarize what was learned\r\n#print(train.word_counts)\r\n#print(train.document_count)\r\n#print(train.word_index)\r\n#print(train.word_docs)\r\n# integer encode documents\r\nXtrain = tok.texts_to_sequences(trainx)\r\n\r\nXtest = tok.texts_to_sequences(testx)\r\n\r\n\r\n\r\n\r\n#Xtrain, y_train = shuffle(Xtrain, Ytrain, random_state=0)\r\n#Xtest, y_test = shuffle(Xtest, Ytest, random_state=0)\r\n\r\n\r\n# encode class values as integers\r\nencoder = LabelEncoder()\r\nencoder.fit(Ytrain)\r\nencoded_Ytrain = encoder.transform(Ytrain)\r\nencoded_Ytest = encoder.transform(Ytest)\r\n# convert integers to dummy variables (i.e. one hot encoded)\r\ny_train = np_utils.to_categorical(encoded_Ytrain)\r\ny_test = np_utils.to_categorical(encoded_Ytest)\r\n\r\nencoder_length = len(y_train[0])\r\nprint(\"length of one hot enconding  \", encoder_length)\r\n\r\nprint('Pad sequences (samples x time)')\r\nx_train = sequence.pad_sequences(Xtrain, maxlen=maxlen)\r\nx_test = sequence.pad_sequences(Xtest, maxlen=maxlen)\r\n\r\nprint('x_train shape:', x_train.shape)\r\nprint('x_test shape:', x_test.shape)","execution_count":0,"outputs":[{"name":"stdout","text":"loading the data...\ndata loaded, processing data...\n","output_type":"stream"},{"name":"stdout","text":"length of one hot enconding   10\nPad sequences (samples x time)\nx_train shape: (169990, 100)\nx_test shape: (20000, 100)\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"25cb971d-8358-4bf4-9b74-8dfd831e6bb2"},"source":"#https://medium.com/datadriveninvestor/deep-learning-techniques-for-text-classification-9392ca9492c7\r\n\r\n\r\nfrom keras.callbacks import EarlyStopping\r\nfrom keras.layers import GRU\r\n\r\nembedding_size = 128\r\ngru_node = 128\r\ndropout = 0.5\r\n\r\n\r\nmodel = Sequential()\r\nmodel.add(Embedding(max_features,embedding_size, input_length=maxlen))\r\n\r\nmodel.add(GRU(gru_node,return_sequences=True, recurrent_dropout=0.2))\r\nmodel.add(Dropout(dropout))\r\nmodel.add(GRU(gru_node, recurrent_dropout=0.2))\r\nmodel.add(Dropout(dropout))\r\nmodel.add(Dense(32, activation='relu'))\r\nmodel.add(Dense(encoder_length, activation='softmax'))\r\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n\r\nepochs = \r\nbatch_size = 64\r\n\r\n\r\nhistory = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\r\n\r\n\r\n\r\nscore, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\r\nprint('Test score:', score)\r\nprint('Test accuracy:', acc)\r\n\r\n","execution_count":0,"outputs":[{"name":"stderr","text":"/opt/venv/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\nTrain on 152991 samples, validate on 16999 samples\nEpoch 1/3\n 65792/152991 [===========>..................] - ETA: 43:02 - loss: 2.0919 - accuracy: 0.2986","output_type":"stream"},{"name":"stdout","text":" 84992/152991 [===============>..............] - ETA: 32:55 - loss: 2.0210 - accuracy: 0.3111","output_type":"stream"},{"name":"stdout","text":"118400/152991 [======================>.......] - ETA: 16:11 - loss: 1.9321 - accuracy: 0.3302","output_type":"stream"},{"name":"stdout","text":"125312/152991 [=======================>......] - ETA: 12:57 - loss: 1.9179 - accuracy: 0.3334","output_type":"stream"},{"name":"stdout","text":"142080/152991 [==========================>...] - ETA: 5:03 - loss: 1.8885 - accuracy: 0.3404","output_type":"stream"},{"name":"stdout","text":"152991/152991 [==============================] - 4321s 28ms/step - loss: 1.8717 - accuracy: 0.3439 - val_loss: 1.8151 - val_accuracy: 0.3467\nEpoch 2/3\n 14464/152991 [=>............................] - ETA: 55:33 - loss: 1.5511 - accuracy: 0.4372","output_type":"stream"},{"name":"stdout","text":"152991/152991 [==============================] - 3608s 24ms/step - loss: 9.6244 - accuracy: 0.4008 - val_loss: 1.8349 - val_accuracy: 0.3406\nEpoch 3/3\n152991/152991 [==============================] - 1930s 13ms/step - loss: 1.6123 - accuracy: 0.4184 - val_loss: 1.7928 - val_accuracy: 0.3511\n20000/20000 [==============================] - 60s 3ms/step\nTest score: 1.775944815826416\nTest accuracy: 0.35315001010894775\n","output_type":"stream"}]}],"nbformat":4,"nbformat_minor":2,"metadata":{"orig_nbformat":2,"deepnote_notebook_id":"e1b0fb41-7cb3-484d-a52d-d3401094c55a","deepnote_execution_queue":[]}}