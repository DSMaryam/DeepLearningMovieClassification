{"cells":[{"cell_type":"code","source":"!ls  /home/jovyan/work/","metadata":{"tags":[],"cell_id":"f95900d1-4181-4d88-8470-c64a80186083"},"outputs":[{"name":"stdout","text":"aclImdb\t\t  model.png\t    plottingnetworks.ipynb  trytoghether.ipynb\r\nangela.ipynb\t  Nathantest.ipynb  Testmodel\t\t    Webscraping.ipynb\r\nangelatry2.ipynb  notebook.ipynb    try3.ipynb\r\ninit.ipynb\t  out5.csv\t    try4.ipynb\r\nmodel_3.png\t  out5.zip\t    try5.ipynb\r\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","metadata":{"tags":[],"cell_id":"1f672a9e-79df-464b-9750-53f86aaeaa03"},"source":"import csv\r\nfrom pathlib import Path \r\nimport numpy as np\r\nfrom keras.preprocessing.text import Tokenizer\r\nfrom sklearn.utils import shuffle\r\nfrom keras.preprocessing import sequence\r\nimport os \r\n\r\nimport tensorflow as tf\r\n\r\nfrom keras import backend\r\nfrom keras.models import Sequential\r\nfrom keras.layers import Dense, Dropout, Activation\r\nfrom keras.layers import Embedding, Reshape\r\nfrom keras.layers import LSTM\r\nfrom keras.layers import Conv1D, MaxPooling1D\r\nfrom keras.utils import np_utils\r\n\r\nfrom sklearn.model_selection import cross_val_score\r\nfrom sklearn.model_selection import KFold\r\nfrom sklearn.preprocessing import LabelEncoder\r\nfrom sklearn.pipeline import Pipeline\r\n","execution_count":1,"outputs":[{"name":"stderr","text":"Using TensorFlow backend.\n","output_type":"stream"}]},{"cell_type":"code","source":"max_features = 20000\r\nmaxlen = 100\r\n\r\n\r\n\r\n\r\n\r\nYtrain=[]\r\ntrainx=[]\r\nYtest=[]\r\ntestx=[]\r\nprint(\"loading the data...\")\r\nwith open('/home/jovyan/work/out7.csv',encoding=\"utf8\") as csv_file:\r\n    csv_reader = csv.reader(csv_file)\r\n    for row in csv_reader:\r\n        if csv_reader.line_num < 55001:\r\n            Ytrain.append(int(row[0].split('/')[0]))\r\n            trainx.append(row[0].split('\\t')[1])\r\n        elif csv_reader.line_num < 59300:\r\n            Ytest.append(int(row[0].split('/')[0]))\r\n            testx.append(row[0].split('\\t')[1]) \r\n        else:\r\n            break    \r\n\r\n\r\n   \r\n\r\n#59378\r\n\r\n\r\nprint(\"data loaded, processing data...\")\r\n\r\n\r\n# create the tokenizer\r\ntok= Tokenizer(num_words=max_features, lower=True,filters='\"#$%&()*+-/:<=>@[\\\\]^_`{|}~\\t\\n',split=' ', char_level=False, oov_token=None, document_count=0)\r\n# fit the tokenizer on the documents\r\ntok.fit_on_texts(trainx)\r\n# summarize what was learned\r\n#print(train.word_counts)\r\n#print(train.document_count)\r\n#print(train.word_index)\r\n#print(train.word_docs)\r\n# integer encode documents\r\nXtrain = tok.texts_to_sequences(trainx)\r\n\r\nXtest = tok.texts_to_sequences(testx)\r\n\r\n\r\n\r\n\r\nXtrain, y_train = shuffle(Xtrain, Ytrain, random_state=0)\r\nXtest, y_test = shuffle(Xtest, Ytest, random_state=0)\r\n\r\n\r\n# encode class values as integers\r\nencoder = LabelEncoder()\r\nencoder.fit(Ytrain)\r\nencoded_Ytrain = encoder.transform(Ytrain)\r\nencoded_Ytest = encoder.transform(Ytest)\r\n# convert integers to dummy variables (i.e. one hot encoded)\r\ny_train = np_utils.to_categorical(encoded_Ytrain)\r\ny_test = np_utils.to_categorical(encoded_Ytest)\r\n\r\nencoder_length = len(y_train[0])\r\nprint(\"length of one hot enconding  \", encoder_length)\r\n\r\nprint('Pad sequences (samples x time)')\r\nx_train = sequence.pad_sequences(Xtrain, maxlen=maxlen)\r\nx_test = sequence.pad_sequences(Xtest, maxlen=maxlen)\r\n\r\nprint('x_train shape:', x_train.shape)\r\nprint('x_test shape:', x_test.shape)\r\n\r\nYtrain = [x-1 for x in Ytrain]\r\nYtest = [x-1 for x in Ytest]\r\n\r\n","metadata":{"tags":[],"cell_id":"d006ab0a-0cc0-4de6-b059-b830dc0d07ff"},"outputs":[{"name":"stdout","text":"loading the data...\n","output_type":"stream"},{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/home/jovyan/work/out7.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-802dc77b47da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtestx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loading the data...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/jovyan/work/out7.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcsv_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mcsv_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcsv_reader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/jovyan/work/out7.csv'"]}],"execution_count":11},{"cell_type":"code","source":"# https://towardsdatascience.com/multi-class-text-classification-with-lstm-1590bee1bd17\r\n\r\nfrom keras.layers import SpatialDropout1D\r\nfrom keras.callbacks import EarlyStopping\r\nfrom keras.metrics import top_k_categorical_accuracy\r\n\r\n\r\nembedding_size = 100\r\n\r\n\r\nmodel = Sequential()\r\nmodel.add(Embedding(max_features,embedding_size, input_length=maxlen))\r\nmodel.add(SpatialDropout1D(0.2))\r\nmodel.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\r\nmodel.add(Dense(encoder_length, activation='softmax'))\r\n\r\nmodel.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n\r\nepochs = 3\r\nbatch_size = 64\r\n\r\n#Ytrain = [x-1 for x in Ytrain]\r\n#Ytest = [x-1 for x in Ytest]\r\n\r\n\r\nhistory2 = model.fit(x_train, Ytrain, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\r\n\r\n\r\n\r\nscore, acc = model.evaluate(x_test, Ytest, batch_size=batch_size)\r\nprint('Test score:', score)\r\nprint('Test accuracy:', acc)\r\n","metadata":{"tags":[],"cell_id":"453d8746-e5c5-45cc-97a4-ef963927bf00"},"outputs":[{"name":"stderr","text":"/opt/venv/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\nTrain on 48004 samples, validate on 5334 samples\nEpoch 1/3\n21824/48004 [============>.................] - ETA: 3:12 - loss: 2.0130 - accuracy: 0.2964","output_type":"stream"},{"name":"stdout","text":"48004/48004 [==============================] - 347s 7ms/step - loss: 2.0005 - accuracy: 0.2993 - val_loss: 2.0804 - val_accuracy: 0.2527\nEpoch 2/3\n48004/48004 [==============================] - 306s 6ms/step - loss: 1.9673 - accuracy: 0.3016 - val_loss: 2.0995 - val_accuracy: 0.2493\nEpoch 3/3\n48004/48004 [==============================] - 303s 6ms/step - loss: 1.8343 - accuracy: 0.3472 - val_loss: 2.1995 - val_accuracy: 0.2175\n4161/4161 [==============================] - 6s 1ms/step\nTest score: 2.1662018654925754\nTest accuracy: 0.23311704397201538\n","output_type":"stream"}],"execution_count":0},{"cell_type":"code","source":"# https://towardsdatascience.com/multi-class-text-classification-with-lstm-1590bee1bd17\r\n\r\n#with the shuffled data\r\n\r\nfrom keras.layers import SpatialDropout1D\r\nfrom keras.callbacks import EarlyStopping\r\nfrom keras.metrics import top_k_categorical_accuracy\r\n\r\n\r\nembedding_size = 100\r\n\r\n\r\nmodel = Sequential()\r\nmodel.add(Embedding(max_features,embedding_size, input_length=maxlen))\r\nmodel.add(SpatialDropout1D(0.2))\r\nmodel.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\r\nmodel.add(Dense(encoder_length, activation='softmax'))\r\n\r\nmodel.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n\r\nepochs = 3\r\nbatch_size = 64\r\n\r\n#Ytrain = [x-1 for x in Ytrain]\r\n#Ytest = [x-1 for x in Ytest]\r\n\r\n\r\nhistory2 = model.fit(x_train, Ytrain, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\r\n\r\n\r\n\r\nscore, acc = model.evaluate(x_test, Ytest, batch_size=batch_size)\r\nprint('Test score:', score)\r\nprint('Test accuracy:', acc)\r\n","metadata":{"tags":[],"cell_id":"1103c4cd-9553-46d5-b2b6-d5b3c150f682"},"outputs":[{"name":"stderr","text":"/opt/venv/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\nTrain on 48004 samples, validate on 5334 samples\nEpoch 1/3\n48004/48004 [==============================] - 313s 7ms/step - loss: 1.9996 - accuracy: 0.2993 - val_loss: 2.0758 - val_accuracy: 0.2527\nEpoch 2/3\n48004/48004 [==============================] - 306s 6ms/step - loss: 1.9687 - accuracy: 0.3020 - val_loss: 2.1035 - val_accuracy: 0.2460\nEpoch 3/3\n48004/48004 [==============================] - 337s 7ms/step - loss: 1.8410 - accuracy: 0.3479 - val_loss: 2.1977 - val_accuracy: 0.2252\n4161/4161 [==============================] - 8s 2ms/step\nTest score: 2.164063237544809\nTest accuracy: 0.24321076273918152\n","output_type":"stream"}],"execution_count":6}],"nbformat":4,"nbformat_minor":2,"metadata":{"orig_nbformat":2,"deepnote_notebook_id":"7694cc8a-a339-42da-9f4c-55834a65f7e3","deepnote_execution_queue":[]}}
